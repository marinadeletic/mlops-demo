{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying the Pipeline\n",
    "This notebook assumes one has created, built and commiting the artifacts required. Here we will deploy only a new pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "**NOTE:** Set Project ID to your project  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'mmlops3'\n",
    "PREFIX = PROJECT_ID\n",
    "REGION = 'us-central1'\n",
    "JOB_DIR_ROOT='gs://{}-artifact-store/jobs'.format(PREFIX)\n",
    "NAMESPACE='kubeflow'\n",
    "ZONE='us-central1-a'\n",
    "ARTIFACT_STORE_URI='gs://{}-artifact-store'.format(PREFIX)\n",
    "GCS_STAGING_PATH='{}/staging'.format(ARTIFACT_STORE_URI)\n",
    "GKE_CLUSTER_NAME='{}-cluster'.format(PREFIX)\n",
    "\n",
    "\n",
    "!gcloud container clusters get-credentials $GKE_CLUSTER_NAME --zone $ZONE\n",
    "HOST_TEMP=!(kubectl describe configmap inverse-proxy-config -n $NAMESPACE | grep \"googleusercontent.com\")\n",
    "INVERSE_PROXY_HOSTNAME=HOST_TEMP[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the pipeline\n",
    "Select a pipeline name, ensure it is not already in use at the allocated hostname (else a 500 error will be displayed). Deploy the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME='covertype_classifier_training_v0'\n",
    "\n",
    "!kfp --endpoint {INVERSE_PROXY_HOSTNAME} pipeline upload -p {PIPELINE_NAME} covertype_training_pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command will return a list of pipelines depolyed at the given hostname. We see that `covertype_classifier_training` has been deployed. This list also allows us to copy the pipeline ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kfp --endpoint {INVERSE_PROXY_HOSTNAME} pipeline list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing the pipeline\n",
    "The deployed pipeline can be viewed through the Kubeflow Pipeline UI given at the URL below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('https://{}'.format(INVERSE_PROXY_HOSTNAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment \n",
    "Now that the pipeline is deployed we want to run an experiment, this will cause the pipeline to run, pulling the data from bigquery and splitting it, training the models, evaluating them and deploy the best performing model. This experiment takes approximately an hour to execute and will result in a deployed model which can be interacted with through GCP's AI platform predicting service. \n",
    "\n",
    "**NOTE:** Change the PIPELINE_ID to reflect the ID copied from above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_ID='d99c0b38-cef2-4056-a6aa-fed4f35dd06c'\n",
    "\n",
    "EXPERIMENT_NAME='Covertype_Classifier_Training_V0'\n",
    "RUN_ID='Run_001'\n",
    "SOURCE_TABLE='covertype_dataset.covertype'\n",
    "DATASET_ID='splits'\n",
    "EVALUATION_METRIC='accuracy'\n",
    "EVALUATION_METRIC_THRESHOLD='0.69'\n",
    "MODEL_ID='covertype_classifier_V0'\n",
    "VERSION_ID='v01'\n",
    "REPLACE_EXISTING_VERSION=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kfp --endpoint {INVERSE_PROXY_HOSTNAME} run submit \\\n",
    "-e {EXPERIMENT_NAME} \\\n",
    "-r {RUN_ID} \\\n",
    "-p {PIPELINE_ID} \\\n",
    "project_id={PROJECT_ID} \\\n",
    "gcs_root={GCS_STAGING_PATH} \\\n",
    "region={REGION} \\\n",
    "source_table_name={SOURCE_TABLE} \\\n",
    "dataset_id={DATASET_ID} \\\n",
    "evaluation_metric_name={EVALUATION_METRIC} \\\n",
    "evaluation_metric_threshold={EVALUATION_METRIC_THRESHOLD} \\\n",
    "model_id={MODEL_ID} \\\n",
    "version_id={VERSION_ID} \\\n",
    "replace_existing_version={REPLACE_EXISTING_VERSION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model\n",
    "To test the model we can use the AI platforms prediction API to ask for a prediction based on a JSON input aternatively we can use the prediction UI and input: *{\"instances\":[[2395,0,0,60,6,1170,218,238,156,1054,\"Cache\",\"C2717\"]]}* in the test case window.\n",
    "\n",
    "We write a prediction JSON file with a set of data points, the correct cover types are 6 and 1 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile predict.json\n",
    "[3366,122,15,789,127,2881,244,227,107,2437,\"Commanche\",\"C8772\"]\n",
    "[2791,340,15,30,10,3906,188,217,168,5401,\"Rawah\",\"C7745\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_FILE=\"./predict.json\"\n",
    "\n",
    "!gcloud ai-platform predict --model {MODEL_ID} \\\n",
    "  --version {VERSION_ID} \\\n",
    "  --json-instances {INPUT_DATA_FILE}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
