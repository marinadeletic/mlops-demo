"apiVersion": |-
  argoproj.io/v1alpha1
"kind": |-
  Workflow
"metadata":
  "annotations":
    "pipelines.kubeflow.org/pipeline_spec": |-
      {"description": "The pipeline training and deploying the Covertype classifierpipeline_yaml", "inputs": [{"name": "project_id"}, {"name": "region"}, {"name": "source_table_name"}, {"name": "gcs_root"}, {"name": "dataset_id"}, {"name": "evaluation_metric_name"}, {"name": "evaluation_metric_threshold"}, {"name": "model_id"}, {"name": "version_id"}, {"name": "replace_existing_version"}, {"default": "\n{\n    \"hyperparameters\":  {\n        \"goal\": \"MAXIMIZE\",\n        \"maxTrials\": 6,\n        \"maxParallelTrials\": 3,\n        \"hyperparameterMetricTag\": \"accuracy\",\n        \"enableTrialEarlyStopping\": True,\n        \"params\": [\n            {\n                \"parameterName\": \"max_iter\",\n                \"type\": \"DISCRETE\",\n                \"discreteValues\": [500, 1000]\n            },\n            {\n                \"parameterName\": \"alpha\",\n                \"type\": \"DOUBLE\",\n                \"minValue\": 0.0001,\n                \"maxValue\": 0.001,\n                \"scaleType\": \"UNIT_LINEAR_SCALE\"\n            }\n        ]\n    }\n}\n", "name": "hypertune_settings"}, {"default": "US", "name": "dataset_location"}], "name": "Covertype Classifier Training"}
  "generateName": |-
    covertype-classifier-training-
"spec":
  "arguments":
    "parameters":
    - "name": |-
        project_id
    - "name": |-
        region
    - "name": |-
        source_table_name
    - "name": |-
        gcs_root
    - "name": |-
        dataset_id
    - "name": |-
        evaluation_metric_name
    - "name": |-
        evaluation_metric_threshold
    - "name": |-
        model_id
    - "name": |-
        version_id
    - "name": |-
        replace_existing_version
    - "name": |-
        hypertune_settings
      "value": |2

        {
            "hyperparameters":  {
                "goal": "MAXIMIZE",
                "maxTrials": 6,
                "maxParallelTrials": 3,
                "hyperparameterMetricTag": "accuracy",
                "enableTrialEarlyStopping": True,
                "params": [
                    {
                        "parameterName": "max_iter",
                        "type": "DISCRETE",
                        "discreteValues": [500, 1000]
                    },
                    {
                        "parameterName": "alpha",
                        "type": "DOUBLE",
                        "minValue": 0.0001,
                        "maxValue": 0.001,
                        "scaleType": "UNIT_LINEAR_SCALE"
                    }
                ]
            }
        }
    - "name": |-
        dataset_location
      "value": |-
        US
  "entrypoint": |-
    covertype-classifier-training
  "serviceAccountName": |-
    pipeline-runner
  "templates":
  - "container":
      "args":
      - |-
        kfp_component.google.bigquery
      - |-
        query
      - |-
        --query
      - "\n       SELECT *\n       FROM \n           `{{inputs.parameters.source_table_name}}`\
        \ AS cover\n       WHERE \n       MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(cover))),\
        \ 10) IN (1, 2, 3, 4)\n       "
      - |-
        --project_id
      - |-
        {{inputs.parameters.project_id}}
      - |-
        --dataset_id
      - |-
        {{inputs.parameters.dataset_id}}
      - |-
        --table_id
      - ""
      - |-
        --dataset_location
      - |-
        {{inputs.parameters.dataset_location}}
      - |-
        --output_gcs_path
      - |-
        {{inputs.parameters.gcs_root}}/datasets/training/data.csv
      - |-
        --job_config
      - ""
      "command": []
      "env":
      - "name": |-
          KFP_POD_NAME
        "value": |-
          {{pod.name}}
      - "name": |-
          KFP_POD_NAME
        "valueFrom":
          "fieldRef":
            "fieldPath": |-
              metadata.name
      - "name": |-
          KFP_NAMESPACE
        "valueFrom":
          "fieldRef":
            "fieldPath": |-
              metadata.namespace
      - "name": |-
          GOOGLE_APPLICATION_CREDENTIALS
        "value": |-
          /secret/gcp-credentials/user-gcp-sa.json
      - "name": |-
          CLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE
        "value": |-
          /secret/gcp-credentials/user-gcp-sa.json
      "image": |-
        gcr.io/ml-pipeline/ml-pipeline-gcp:9ad7d7dd9776ce75a83712f5723db2ef93ba5c26
      "volumeMounts":
      - "mountPath": |-
          /secret/gcp-credentials
        "name": |-
          gcp-credentials-user-gcp-sa
    "inputs":
      "parameters":
      - "name": |-
          dataset_id
      - "name": |-
          dataset_location
      - "name": |-
          gcs_root
      - "name": |-
          project_id
      - "name": |-
          source_table_name
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"description": "A Kubeflow Pipeline component to submit a query to Google Cloud Bigquery \nservice and dump outputs to a Google Cloud Storage blob. \n", "inputs": [{"description": "The query used by Bigquery service to fetch the results.", "name": "query", "type": "String"}, {"description": "The project to execute the query job.", "name": "project_id", "type": "GCPProjectID"}, {"default": "", "description": "The ID of the persistent dataset to keep the results of the query.", "name": "dataset_id", "type": "String"}, {"default": "", "description": "The ID of the table to keep the results of the query. If absent, the operation will generate a random id for the table.", "name": "table_id", "type": "String"}, {"default": "", "description": "The path to the Cloud Storage bucket to store the query output.", "name": "output_gcs_path", "type": "GCSPath"}, {"default": "US", "description": "The location to create the dataset. Defaults to `US`.", "name": "dataset_location", "type": "String"}, {"default": "", "description": "The full config spec for the query job.See  [QueryJobConfig](https://googleapis.github.io/google-cloud-python/latest/bigquery/generated/google.cloud.bigquery.job.QueryJobConfig.html#google.cloud.bigquery.job.QueryJobConfig)  for details.", "name": "job_config", "type": "Dict"}], "metadata": {"labels": {"add-pod-env": "true"}}, "name": "Bigquery - Query", "outputs": [{"description": "The path to the Cloud Storage bucket containing the query output in CSV format.", "name": "output_gcs_path", "type": "GCSPath"}, {"name": "MLPipeline UI metadata", "type": "UI metadata"}]}
      "labels":
        "add-pod-env": |-
          true
    "name": |-
      bigquery-query
    "outputs":
      "artifacts":
      - "name": |-
          mlpipeline-ui-metadata
        "path": |-
          /mlpipeline-ui-metadata.json
      - "name": |-
          bigquery-query-output_gcs_path
        "path": |-
          /tmp/kfp/output/bigquery/query-output-path.txt
      "parameters":
      - "name": |-
          bigquery-query-output_gcs_path
        "valueFrom":
          "path": |-
            /tmp/kfp/output/bigquery/query-output-path.txt
    "volumes":
    - "name": |-
        gcp-credentials-user-gcp-sa
      "secret":
        "secretName": |-
          user-gcp-sa
  - "container":
      "args":
      - |-
        kfp_component.google.bigquery
      - |-
        query
      - |-
        --query
      - "\n       SELECT *\n       FROM \n           `{{inputs.parameters.source_table_name}}`\
        \ AS cover\n       WHERE \n       MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(cover))),\
        \ 10) IN (8)\n       "
      - |-
        --project_id
      - |-
        {{inputs.parameters.project_id}}
      - |-
        --dataset_id
      - |-
        {{inputs.parameters.dataset_id}}
      - |-
        --table_id
      - ""
      - |-
        --dataset_location
      - |-
        {{inputs.parameters.dataset_location}}
      - |-
        --output_gcs_path
      - |-
        {{inputs.parameters.gcs_root}}/datasets/validation/data.csv
      - |-
        --job_config
      - ""
      "command": []
      "env":
      - "name": |-
          KFP_POD_NAME
        "value": |-
          {{pod.name}}
      - "name": |-
          KFP_POD_NAME
        "valueFrom":
          "fieldRef":
            "fieldPath": |-
              metadata.name
      - "name": |-
          KFP_NAMESPACE
        "valueFrom":
          "fieldRef":
            "fieldPath": |-
              metadata.namespace
      - "name": |-
          GOOGLE_APPLICATION_CREDENTIALS
        "value": |-
          /secret/gcp-credentials/user-gcp-sa.json
      - "name": |-
          CLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE
        "value": |-
          /secret/gcp-credentials/user-gcp-sa.json
      "image": |-
        gcr.io/ml-pipeline/ml-pipeline-gcp:9ad7d7dd9776ce75a83712f5723db2ef93ba5c26
      "volumeMounts":
      - "mountPath": |-
          /secret/gcp-credentials
        "name": |-
          gcp-credentials-user-gcp-sa
    "inputs":
      "parameters":
      - "name": |-
          dataset_id
      - "name": |-
          dataset_location
      - "name": |-
          gcs_root
      - "name": |-
          project_id
      - "name": |-
          source_table_name
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"description": "A Kubeflow Pipeline component to submit a query to Google Cloud Bigquery \nservice and dump outputs to a Google Cloud Storage blob. \n", "inputs": [{"description": "The query used by Bigquery service to fetch the results.", "name": "query", "type": "String"}, {"description": "The project to execute the query job.", "name": "project_id", "type": "GCPProjectID"}, {"default": "", "description": "The ID of the persistent dataset to keep the results of the query.", "name": "dataset_id", "type": "String"}, {"default": "", "description": "The ID of the table to keep the results of the query. If absent, the operation will generate a random id for the table.", "name": "table_id", "type": "String"}, {"default": "", "description": "The path to the Cloud Storage bucket to store the query output.", "name": "output_gcs_path", "type": "GCSPath"}, {"default": "US", "description": "The location to create the dataset. Defaults to `US`.", "name": "dataset_location", "type": "String"}, {"default": "", "description": "The full config spec for the query job.See  [QueryJobConfig](https://googleapis.github.io/google-cloud-python/latest/bigquery/generated/google.cloud.bigquery.job.QueryJobConfig.html#google.cloud.bigquery.job.QueryJobConfig)  for details.", "name": "job_config", "type": "Dict"}], "metadata": {"labels": {"add-pod-env": "true"}}, "name": "Bigquery - Query", "outputs": [{"description": "The path to the Cloud Storage bucket containing the query output in CSV format.", "name": "output_gcs_path", "type": "GCSPath"}, {"name": "MLPipeline UI metadata", "type": "UI metadata"}]}
      "labels":
        "add-pod-env": |-
          true
    "name": |-
      bigquery-query-2
    "outputs":
      "artifacts":
      - "name": |-
          mlpipeline-ui-metadata
        "path": |-
          /mlpipeline-ui-metadata.json
      - "name": |-
          bigquery-query-2-output_gcs_path
        "path": |-
          /tmp/kfp/output/bigquery/query-output-path.txt
      "parameters":
      - "name": |-
          bigquery-query-2-output_gcs_path
        "valueFrom":
          "path": |-
            /tmp/kfp/output/bigquery/query-output-path.txt
    "volumes":
    - "name": |-
        gcp-credentials-user-gcp-sa
      "secret":
        "secretName": |-
          user-gcp-sa
  - "container":
      "args":
      - |-
        kfp_component.google.bigquery
      - |-
        query
      - |-
        --query
      - "\n       SELECT *\n       FROM \n           `{{inputs.parameters.source_table_name}}`\
        \ AS cover\n       WHERE \n       MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(cover))),\
        \ 10) IN (9)\n       "
      - |-
        --project_id
      - |-
        {{inputs.parameters.project_id}}
      - |-
        --dataset_id
      - |-
        {{inputs.parameters.dataset_id}}
      - |-
        --table_id
      - ""
      - |-
        --dataset_location
      - |-
        {{inputs.parameters.dataset_location}}
      - |-
        --output_gcs_path
      - |-
        {{inputs.parameters.gcs_root}}/datasets/testing/data.csv
      - |-
        --job_config
      - ""
      "command": []
      "env":
      - "name": |-
          KFP_POD_NAME
        "value": |-
          {{pod.name}}
      - "name": |-
          KFP_POD_NAME
        "valueFrom":
          "fieldRef":
            "fieldPath": |-
              metadata.name
      - "name": |-
          KFP_NAMESPACE
        "valueFrom":
          "fieldRef":
            "fieldPath": |-
              metadata.namespace
      - "name": |-
          GOOGLE_APPLICATION_CREDENTIALS
        "value": |-
          /secret/gcp-credentials/user-gcp-sa.json
      - "name": |-
          CLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE
        "value": |-
          /secret/gcp-credentials/user-gcp-sa.json
      "image": |-
        gcr.io/ml-pipeline/ml-pipeline-gcp:9ad7d7dd9776ce75a83712f5723db2ef93ba5c26
      "volumeMounts":
      - "mountPath": |-
          /secret/gcp-credentials
        "name": |-
          gcp-credentials-user-gcp-sa
    "inputs":
      "parameters":
      - "name": |-
          dataset_id
      - "name": |-
          dataset_location
      - "name": |-
          gcs_root
      - "name": |-
          project_id
      - "name": |-
          source_table_name
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"description": "A Kubeflow Pipeline component to submit a query to Google Cloud Bigquery \nservice and dump outputs to a Google Cloud Storage blob. \n", "inputs": [{"description": "The query used by Bigquery service to fetch the results.", "name": "query", "type": "String"}, {"description": "The project to execute the query job.", "name": "project_id", "type": "GCPProjectID"}, {"default": "", "description": "The ID of the persistent dataset to keep the results of the query.", "name": "dataset_id", "type": "String"}, {"default": "", "description": "The ID of the table to keep the results of the query. If absent, the operation will generate a random id for the table.", "name": "table_id", "type": "String"}, {"default": "", "description": "The path to the Cloud Storage bucket to store the query output.", "name": "output_gcs_path", "type": "GCSPath"}, {"default": "US", "description": "The location to create the dataset. Defaults to `US`.", "name": "dataset_location", "type": "String"}, {"default": "", "description": "The full config spec for the query job.See  [QueryJobConfig](https://googleapis.github.io/google-cloud-python/latest/bigquery/generated/google.cloud.bigquery.job.QueryJobConfig.html#google.cloud.bigquery.job.QueryJobConfig)  for details.", "name": "job_config", "type": "Dict"}], "metadata": {"labels": {"add-pod-env": "true"}}, "name": "Bigquery - Query", "outputs": [{"description": "The path to the Cloud Storage bucket containing the query output in CSV format.", "name": "output_gcs_path", "type": "GCSPath"}, {"name": "MLPipeline UI metadata", "type": "UI metadata"}]}
      "labels":
        "add-pod-env": |-
          true
    "name": |-
      bigquery-query-3
    "outputs":
      "artifacts":
      - "name": |-
          mlpipeline-ui-metadata
        "path": |-
          /mlpipeline-ui-metadata.json
      - "name": |-
          bigquery-query-3-output_gcs_path
        "path": |-
          /tmp/kfp/output/bigquery/query-output-path.txt
      "parameters":
      - "name": |-
          bigquery-query-3-output_gcs_path
        "valueFrom":
          "path": |-
            /tmp/kfp/output/bigquery/query-output-path.txt
    "volumes":
    - "name": |-
        gcp-credentials-user-gcp-sa
      "secret":
        "secretName": |-
          user-gcp-sa
  - "dag":
      "tasks":
      - "arguments":
          "parameters":
          - "name": |-
              model_id
            "value": |-
              {{inputs.parameters.model_id}}
          - "name": |-
              project_id
            "value": |-
              {{inputs.parameters.project_id}}
          - "name": |-
              replace_existing_version
            "value": |-
              {{inputs.parameters.replace_existing_version}}
          - "name": |-
              submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir
            "value": |-
              {{inputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}
          - "name": |-
              version_id
            "value": |-
              {{inputs.parameters.version_id}}
        "name": |-
          deploying-a-trained-model-to-cloud-machine-learning-engine
        "template": |-
          deploying-a-trained-model-to-cloud-machine-learning-engine
    "inputs":
      "parameters":
      - "name": |-
          model_id
      - "name": |-
          project_id
      - "name": |-
          replace_existing_version
      - "name": |-
          submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir
      - "name": |-
          version_id
    "name": |-
      condition-1
  - "dag":
      "tasks":
      - "arguments":
          "parameters":
          - "name": |-
              dataset_id
            "value": |-
              {{inputs.parameters.dataset_id}}
          - "name": |-
              dataset_location
            "value": |-
              {{inputs.parameters.dataset_location}}
          - "name": |-
              gcs_root
            "value": |-
              {{inputs.parameters.gcs_root}}
          - "name": |-
              project_id
            "value": |-
              {{inputs.parameters.project_id}}
          - "name": |-
              source_table_name
            "value": |-
              {{inputs.parameters.source_table_name}}
        "name": |-
          bigquery-query
        "template": |-
          bigquery-query
      - "arguments":
          "parameters":
          - "name": |-
              dataset_id
            "value": |-
              {{inputs.parameters.dataset_id}}
          - "name": |-
              dataset_location
            "value": |-
              {{inputs.parameters.dataset_location}}
          - "name": |-
              gcs_root
            "value": |-
              {{inputs.parameters.gcs_root}}
          - "name": |-
              project_id
            "value": |-
              {{inputs.parameters.project_id}}
          - "name": |-
              source_table_name
            "value": |-
              {{inputs.parameters.source_table_name}}
        "name": |-
          bigquery-query-2
        "template": |-
          bigquery-query-2
      - "arguments":
          "parameters":
          - "name": |-
              dataset_id
            "value": |-
              {{inputs.parameters.dataset_id}}
          - "name": |-
              dataset_location
            "value": |-
              {{inputs.parameters.dataset_location}}
          - "name": |-
              gcs_root
            "value": |-
              {{inputs.parameters.gcs_root}}
          - "name": |-
              project_id
            "value": |-
              {{inputs.parameters.project_id}}
          - "name": |-
              source_table_name
            "value": |-
              {{inputs.parameters.source_table_name}}
        "name": |-
          bigquery-query-3
        "template": |-
          bigquery-query-3
      - "arguments":
          "parameters":
          - "name": |-
              model_id
            "value": |-
              {{inputs.parameters.model_id}}
          - "name": |-
              project_id
            "value": |-
              {{inputs.parameters.project_id}}
          - "name": |-
              replace_existing_version
            "value": |-
              {{inputs.parameters.replace_existing_version}}
          - "name": |-
              submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir
            "value": |-
              {{tasks.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2.outputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}
          - "name": |-
              version_id
            "value": |-
              {{inputs.parameters.version_id}}
        "dependencies":
        - |-
          evaluate-model
        - |-
          submitting-a-cloud-ml-training-job-as-a-pipeline-step-2
        "name": |-
          condition-1
        "template": |-
          condition-1
        "when": |-
          {{tasks.evaluate-model.outputs.parameters.evaluate-model-metric_value}} > {{inputs.parameters.evaluation_metric_threshold}}
      - "arguments":
          "parameters":
          - "name": |-
              bigquery-query-3-output_gcs_path
            "value": |-
              {{tasks.bigquery-query-3.outputs.parameters.bigquery-query-3-output_gcs_path}}
          - "name": |-
              evaluation_metric_name
            "value": |-
              {{inputs.parameters.evaluation_metric_name}}
          - "name": |-
              submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir
            "value": |-
              {{tasks.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2.outputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}
        "dependencies":
        - |-
          bigquery-query-3
        - |-
          submitting-a-cloud-ml-training-job-as-a-pipeline-step-2
        "name": |-
          evaluate-model
        "template": |-
          evaluate-model
      - "arguments":
          "parameters":
          - "name": |-
              project_id
            "value": |-
              {{inputs.parameters.project_id}}
          - "name": |-
              submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id
            "value": |-
              {{tasks.submitting-a-cloud-ml-training-job-as-a-pipeline-step.outputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id}}
        "dependencies":
        - |-
          submitting-a-cloud-ml-training-job-as-a-pipeline-step
        "name": |-
          retrieve-best-run
        "template": |-
          retrieve-best-run
      - "arguments":
          "parameters":
          - "name": |-
              bigquery-query-2-output_gcs_path
            "value": |-
              {{tasks.bigquery-query-2.outputs.parameters.bigquery-query-2-output_gcs_path}}
          - "name": |-
              bigquery-query-output_gcs_path
            "value": |-
              {{tasks.bigquery-query.outputs.parameters.bigquery-query-output_gcs_path}}
          - "name": |-
              gcs_root
            "value": |-
              {{inputs.parameters.gcs_root}}
          - "name": |-
              hypertune_settings
            "value": |-
              {{inputs.parameters.hypertune_settings}}
          - "name": |-
              project_id
            "value": |-
              {{inputs.parameters.project_id}}
          - "name": |-
              region
            "value": |-
              {{inputs.parameters.region}}
        "dependencies":
        - |-
          bigquery-query
        - |-
          bigquery-query-2
        "name": |-
          submitting-a-cloud-ml-training-job-as-a-pipeline-step
        "template": |-
          submitting-a-cloud-ml-training-job-as-a-pipeline-step
      - "arguments":
          "parameters":
          - "name": |-
              bigquery-query-2-output_gcs_path
            "value": |-
              {{tasks.bigquery-query-2.outputs.parameters.bigquery-query-2-output_gcs_path}}
          - "name": |-
              bigquery-query-output_gcs_path
            "value": |-
              {{tasks.bigquery-query.outputs.parameters.bigquery-query-output_gcs_path}}
          - "name": |-
              gcs_root
            "value": |-
              {{inputs.parameters.gcs_root}}
          - "name": |-
              project_id
            "value": |-
              {{inputs.parameters.project_id}}
          - "name": |-
              region
            "value": |-
              {{inputs.parameters.region}}
          - "name": |-
              retrieve-best-run-alpha
            "value": |-
              {{tasks.retrieve-best-run.outputs.parameters.retrieve-best-run-alpha}}
          - "name": |-
              retrieve-best-run-max_iter
            "value": |-
              {{tasks.retrieve-best-run.outputs.parameters.retrieve-best-run-max_iter}}
        "dependencies":
        - |-
          bigquery-query
        - |-
          bigquery-query-2
        - |-
          retrieve-best-run
        "name": |-
          submitting-a-cloud-ml-training-job-as-a-pipeline-step-2
        "template": |-
          submitting-a-cloud-ml-training-job-as-a-pipeline-step-2
    "inputs":
      "parameters":
      - "name": |-
          dataset_id
      - "name": |-
          dataset_location
      - "name": |-
          evaluation_metric_name
      - "name": |-
          evaluation_metric_threshold
      - "name": |-
          gcs_root
      - "name": |-
          hypertune_settings
      - "name": |-
          model_id
      - "name": |-
          project_id
      - "name": |-
          region
      - "name": |-
          replace_existing_version
      - "name": |-
          source_table_name
      - "name": |-
          version_id
    "name": |-
      covertype-classifier-training
  - "container":
      "args":
      - |-
        kfp_component.google.ml_engine
      - |-
        deploy
      - |-
        --model_uri
      - |-
        {{inputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}
      - |-
        --project_id
      - |-
        {{inputs.parameters.project_id}}
      - |-
        --model_id
      - |-
        {{inputs.parameters.model_id}}
      - |-
        --version_id
      - |-
        {{inputs.parameters.version_id}}
      - |-
        --runtime_version
      - |-
        1.14
      - |-
        --python_version
      - |-
        3.5
      - |-
        --model
      - ""
      - |-
        --version
      - ""
      - |-
        --replace_existing_version
      - |-
        {{inputs.parameters.replace_existing_version}}
      - |-
        --set_default
      - |-
        False
      - |-
        --wait_interval
      - |-
        30
      "command": []
      "env":
      - "name": |-
          KFP_POD_NAME
        "value": |-
          {{pod.name}}
      - "name": |-
          KFP_POD_NAME
        "valueFrom":
          "fieldRef":
            "fieldPath": |-
              metadata.name
      - "name": |-
          KFP_NAMESPACE
        "valueFrom":
          "fieldRef":
            "fieldPath": |-
              metadata.namespace
      - "name": |-
          GOOGLE_APPLICATION_CREDENTIALS
        "value": |-
          /secret/gcp-credentials/user-gcp-sa.json
      - "name": |-
          CLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE
        "value": |-
          /secret/gcp-credentials/user-gcp-sa.json
      "image": |-
        gcr.io/ml-pipeline/ml-pipeline-gcp:9ad7d7dd9776ce75a83712f5723db2ef93ba5c26
      "volumeMounts":
      - "mountPath": |-
          /secret/gcp-credentials
        "name": |-
          gcp-credentials-user-gcp-sa
    "inputs":
      "parameters":
      - "name": |-
          model_id
      - "name": |-
          project_id
      - "name": |-
          replace_existing_version
      - "name": |-
          submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir
      - "name": |-
          version_id
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"description": "A Kubeflow Pipeline component to deploy a trained model from a Cloud Storage\npath to a Cloud Machine Learning Engine service.\n", "inputs": [{"description": "Required. The Cloud Storage URI which contains a model file. Commonly  used TF model search paths (export/exporter) will be used if they exist.", "name": "model_uri", "type": "GCSPath"}, {"description": "Required.The ID of the parent project of the serving model.", "name": "project_id", "type": "GCPProjectID"}, {"default": "", "description": "Optional. The user-specified name of the model. If it is not provided,  the operation uses a random name.", "name": "model_id", "type": "String"}, {"default": "", "description": "Optional. The user-specified name of the version. If it is not provided,  the operation uses a random name.", "name": "version_id", "type": "String"}, {"default": "", "description": "Optional. The [Cloud ML Engine runtime version](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list) to use for  this deployment. If it is not set, the Cloud ML Engine uses the default  stable version, 1.0.", "name": "runtime_version", "type": "String"}, {"default": "", "description": "Optional. The version of Python used in the prediction. If it is not set,  the default version is `2.7`. Python `3.5` is available when the  runtime_version is set to `1.4` and above. Python `2.7` works with all  supported runtime versions.", "name": "python_version", "type": "String"}, {"default": "", "description": "Optional. The JSON payload of the new  [Model](https://cloud.google.com/ml-engine/reference/rest/v1/projects.models), if it does not exist.", "name": "model", "type": "Dict"}, {"default": "", "description": "Optional. The JSON payload of the new  [Version](https://cloud.google.com/ml-engine/reference/rest/v1/projects.models.versions).", "name": "version", "type": "Dict"}, {"default": "Fasle", "description": "A Boolean flag that indicates whether to replace existing version in case of conflict.", "name": "replace_existing_version", "type": "Bool"}, {"default": "False", "description": "A Boolean flag that indicates whether to set the new version as default version in the model.", "name": "set_default", "type": "Bool"}, {"default": "30", "description": "A time-interval to wait for in case the operation has a long run time.", "name": "wait_interval", "type": "Integer"}], "metadata": {"labels": {"add-pod-env": "true"}}, "name": "Deploying a trained model to Cloud Machine Learning Engine", "outputs": [{"description": "The Cloud Storage URI of the trained model.", "name": "model_uri", "type": "GCSPath"}, {"description": "The name of the deployed model.", "name": "model_name", "type": "String"}, {"description": "The name of the deployed version.", "name": "version_name", "type": "String"}, {"name": "MLPipeline UI metadata", "type": "UI metadata"}]}
      "labels":
        "add-pod-env": |-
          true
    "name": |-
      deploying-a-trained-model-to-cloud-machine-learning-engine
    "outputs":
      "artifacts":
      - "name": |-
          mlpipeline-ui-metadata
        "path": |-
          /mlpipeline-ui-metadata.json
      - "name": |-
          deploying-a-trained-model-to-cloud-machine-learning-engine-model_name
        "path": |-
          /tmp/kfp/output/ml_engine/model_name.txt
      - "name": |-
          deploying-a-trained-model-to-cloud-machine-learning-engine-model_uri
        "path": |-
          /tmp/kfp/output/ml_engine/model_uri.txt
      - "name": |-
          deploying-a-trained-model-to-cloud-machine-learning-engine-version_name
        "path": |-
          /tmp/kfp/output/ml_engine/version_name.txt
    "volumes":
    - "name": |-
        gcp-credentials-user-gcp-sa
      "secret":
        "secretName": |-
          user-gcp-sa
  - "container":
      "args":
      - |-
        --dataset-path
      - |-
        {{inputs.parameters.bigquery-query-3-output_gcs_path}}
      - |-
        --model-path
      - |-
        {{inputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}
      - |-
        --metric-name
      - |-
        {{inputs.parameters.evaluation_metric_name}}
      - |-
        ----output-paths
      - |-
        /tmp/outputs/metric_name/data
      - |-
        /tmp/outputs/metric_value/data
      - |-
        /tmp/outputs/mlpipeline_metrics/data
      "command":
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - |
        from typing import NamedTuple

        def evaluate_model(
            dataset_path: str, model_path: str, metric_name: str
        ) -> NamedTuple('Outputs', [('metric_name', str), ('metric_value', float),
                                    ('mlpipeline_metrics', 'Metrics')]):
          """Evaluates a trained sklearn model."""
          #import joblib
          import pickle
          import json
          import pandas as pd
          import subprocess
          import sys

          from sklearn.metrics import accuracy_score, recall_score

          df_test = pd.read_csv(dataset_path)

          X_test = df_test.drop('Cover_Type', axis=1)
          y_test = df_test['Cover_Type']

          # Copy the model from GCS
          model_filename = 'model.pkl'
          gcs_model_filepath = '{}/{}'.format(model_path, model_filename)
          print(gcs_model_filepath)
          subprocess.check_call(['gsutil', 'cp', gcs_model_filepath, model_filename],
                                stderr=sys.stdout)

          with open(model_filename, 'rb') as model_file:
            model = pickle.load(model_file)

          y_hat = model.predict(X_test)

          if metric_name == 'accuracy':
            metric_value = accuracy_score(y_test, y_hat)
          elif metric_name == 'recall':
            metric_value = recall_score(y_test, y_hat)
          else:
            metric_name = 'N/A'
            metric_value = 0

          # Export the metric
          metrics = {
              'metrics': [{
                  'name': metric_name,
                  'numberValue': float(metric_value)
              }]
          }

          return (metric_name, metric_value, json.dumps(metrics))

        def _serialize_float(float_value: float) -> str:
            if isinstance(float_value, str):
                return float_value
            if not isinstance(float_value, (float, int)):
                raise TypeError('Value "{}" has type "{}" instead of float.'.format(str(float_value), str(type(float_value))))
            return str(float_value)

        def _serialize_str(str_value: str) -> str:
            if not isinstance(str_value, str):
                raise TypeError('Value "{}" has type "{}" instead of str.'.format(str(str_value), str(type(str_value))))
            return str_value

        import argparse
        _parser = argparse.ArgumentParser(prog='Evaluate model', description='Evaluates a trained sklearn model.\n')
        _parser.add_argument("--dataset-path", dest="dataset_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--model-path", dest="model_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--metric-name", dest="metric_name", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=3)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = evaluate_model(**_parsed_args)

        if not hasattr(_outputs, '__getitem__') or isinstance(_outputs, str):
            _outputs = [_outputs]

        _output_serializers = [
            _serialize_str,
            _serialize_float,
            str,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      "env":
      - "name": |-
          GOOGLE_APPLICATION_CREDENTIALS
        "value": |-
          /secret/gcp-credentials/user-gcp-sa.json
      - "name": |-
          CLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE
        "value": |-
          /secret/gcp-credentials/user-gcp-sa.json
      "image": |-
        gcr.io/marinas-demo/base_image:latest
      "volumeMounts":
      - "mountPath": |-
          /secret/gcp-credentials
        "name": |-
          gcp-credentials-user-gcp-sa
    "inputs":
      "parameters":
      - "name": |-
          bigquery-query-3-output_gcs_path
      - "name": |-
          evaluation_metric_name
      - "name": |-
          submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"description": "Evaluates a trained sklearn model.\n", "inputs": [{"name": "dataset_path", "type": "String"}, {"name": "model_path", "type": "String"}, {"name": "metric_name", "type": "String"}], "name": "Evaluate model", "outputs": [{"name": "metric_name", "type": "String"}, {"name": "metric_value", "type": "Float"}, {"name": "mlpipeline_metrics", "type": "Metrics"}]}
    "name": |-
      evaluate-model
    "outputs":
      "artifacts":
      - "name": |-
          mlpipeline-metrics
        "path": |-
          /tmp/outputs/mlpipeline_metrics/data
      - "name": |-
          evaluate-model-metric_name
        "path": |-
          /tmp/outputs/metric_name/data
      - "name": |-
          evaluate-model-metric_value
        "path": |-
          /tmp/outputs/metric_value/data
      "parameters":
      - "name": |-
          evaluate-model-metric_value
        "valueFrom":
          "path": |-
            /tmp/outputs/metric_value/data
    "volumes":
    - "name": |-
        gcp-credentials-user-gcp-sa
      "secret":
        "secretName": |-
          user-gcp-sa
  - "container":
      "args":
      - |-
        --project-id
      - |-
        {{inputs.parameters.project_id}}
      - |-
        --job-id
      - |-
        {{inputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id}}
      - |-
        ----output-paths
      - |-
        /tmp/outputs/metric_value/data
      - |-
        /tmp/outputs/alpha/data
      - |-
        /tmp/outputs/max_iter/data
      "command":
      - |-
        python3
      - |-
        -u
      - |-
        -c
      - |
        from typing import NamedTuple

        def retrieve_best_run(
            project_id: str, job_id: str
        ) -> NamedTuple('Outputs', [('metric_value', float), ('alpha', float),
                                    ('max_iter', int)]):
          """Retrieves the parameters of the best Hypertune run."""

          from googleapiclient import discovery
          from googleapiclient import errors

          ml = discovery.build('ml', 'v1')

          job_name = 'projects/{}/jobs/{}'.format(project_id, job_id)
          request = ml.projects().jobs().get(name=job_name)

          try:
            response = request.execute()
          except errors.HttpError as err:
            print(err)
          except:
            print('Unexpected error')

          print(response)

          best_trial = response['trainingOutput']['trials'][0]

          metric_value = best_trial['finalMetric']['objectiveValue']
          alpha = float(best_trial['hyperparameters']['alpha'])
          max_iter = int(best_trial['hyperparameters']['max_iter'])

          return (metric_value, alpha, max_iter)

        def _serialize_float(float_value: float) -> str:
            if isinstance(float_value, str):
                return float_value
            if not isinstance(float_value, (float, int)):
                raise TypeError('Value "{}" has type "{}" instead of float.'.format(str(float_value), str(type(float_value))))
            return str(float_value)

        def _serialize_int(int_value: int) -> str:
            if isinstance(int_value, str):
                return int_value
            if not isinstance(int_value, int):
                raise TypeError('Value "{}" has type "{}" instead of int.'.format(str(int_value), str(type(int_value))))
            return str(int_value)

        import argparse
        _parser = argparse.ArgumentParser(prog='Retrieve best run', description='Retrieves the parameters of the best Hypertune run.\n')
        _parser.add_argument("--project-id", dest="project_id", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--job-id", dest="job_id", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=3)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = retrieve_best_run(**_parsed_args)

        if not hasattr(_outputs, '__getitem__') or isinstance(_outputs, str):
            _outputs = [_outputs]

        _output_serializers = [
            _serialize_float,
            _serialize_float,
            _serialize_int,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      "env":
      - "name": |-
          GOOGLE_APPLICATION_CREDENTIALS
        "value": |-
          /secret/gcp-credentials/user-gcp-sa.json
      - "name": |-
          CLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE
        "value": |-
          /secret/gcp-credentials/user-gcp-sa.json
      "image": |-
        gcr.io/marinas-demo/base_image:latest
      "volumeMounts":
      - "mountPath": |-
          /secret/gcp-credentials
        "name": |-
          gcp-credentials-user-gcp-sa
    "inputs":
      "parameters":
      - "name": |-
          project_id
      - "name": |-
          submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"description": "Retrieves the parameters of the best Hypertune run.\n", "inputs": [{"name": "project_id", "type": "String"}, {"name": "job_id", "type": "String"}], "name": "Retrieve best run", "outputs": [{"name": "metric_value", "type": "Float"}, {"name": "alpha", "type": "Float"}, {"name": "max_iter", "type": "Integer"}]}
    "name": |-
      retrieve-best-run
    "outputs":
      "artifacts":
      - "name": |-
          retrieve-best-run-alpha
        "path": |-
          /tmp/outputs/alpha/data
      - "name": |-
          retrieve-best-run-max_iter
        "path": |-
          /tmp/outputs/max_iter/data
      - "name": |-
          retrieve-best-run-metric_value
        "path": |-
          /tmp/outputs/metric_value/data
      "parameters":
      - "name": |-
          retrieve-best-run-alpha
        "valueFrom":
          "path": |-
            /tmp/outputs/alpha/data
      - "name": |-
          retrieve-best-run-max_iter
        "valueFrom":
          "path": |-
            /tmp/outputs/max_iter/data
    "volumes":
    - "name": |-
        gcp-credentials-user-gcp-sa
      "secret":
        "secretName": |-
          user-gcp-sa
  - "container":
      "args":
      - |-
        kfp_component.google.ml_engine
      - |-
        train
      - |-
        --project_id
      - |-
        {{inputs.parameters.project_id}}
      - |-
        --python_module
      - ""
      - |-
        --package_uris
      - ""
      - |-
        --region
      - |-
        {{inputs.parameters.region}}
      - |-
        --args
      - |-
        ["--training_dataset_path", "{{inputs.parameters.bigquery-query-output_gcs_path}}", "--validation_dataset_path", "{{inputs.parameters.bigquery-query-2-output_gcs_path}}", "--hptune", "True"]
      - |-
        --job_dir
      - |-
        {{inputs.parameters.gcs_root}}/jobdir/hypertune/{{workflow.uid}}
      - |-
        --python_version
      - ""
      - |-
        --runtime_version
      - ""
      - |-
        --master_image_uri
      - |-
        gcr.io/marinas-demo/trainer_image:latest
      - |-
        --worker_image_uri
      - ""
      - |-
        --training_input
      - |-
        {{inputs.parameters.hypertune_settings}}
      - |-
        --job_id_prefix
      - ""
      - |-
        --wait_interval
      - |-
        30
      "command": []
      "env":
      - "name": |-
          KFP_POD_NAME
        "value": |-
          {{pod.name}}
      - "name": |-
          KFP_POD_NAME
        "valueFrom":
          "fieldRef":
            "fieldPath": |-
              metadata.name
      - "name": |-
          KFP_NAMESPACE
        "valueFrom":
          "fieldRef":
            "fieldPath": |-
              metadata.namespace
      - "name": |-
          GOOGLE_APPLICATION_CREDENTIALS
        "value": |-
          /secret/gcp-credentials/user-gcp-sa.json
      - "name": |-
          CLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE
        "value": |-
          /secret/gcp-credentials/user-gcp-sa.json
      "image": |-
        gcr.io/ml-pipeline/ml-pipeline-gcp:9ad7d7dd9776ce75a83712f5723db2ef93ba5c26
      "volumeMounts":
      - "mountPath": |-
          /secret/gcp-credentials
        "name": |-
          gcp-credentials-user-gcp-sa
    "inputs":
      "parameters":
      - "name": |-
          bigquery-query-2-output_gcs_path
      - "name": |-
          bigquery-query-output_gcs_path
      - "name": |-
          gcs_root
      - "name": |-
          hypertune_settings
      - "name": |-
          project_id
      - "name": |-
          region
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"description": "A Kubeflow Pipeline component to submit a Cloud Machine Learning (Cloud ML) \nEngine training job as a step in a pipeline.\n", "inputs": [{"description": "Required. The ID of the parent project of the job.", "name": "project_id", "type": "GCPProjectID"}, {"default": "", "description": "The Python module name to run after installing the packages.", "name": "python_module", "type": "String"}, {"default": "", "description": "The Cloud Storage location of the packages (that contain the training program  and any additional dependencies). The maximum number of package URIs is 100.", "name": "package_uris", "type": "List"}, {"default": "", "description": "The Compute Engine region in which the training job is run.", "name": "region", "type": "GCPRegion"}, {"default": "", "description": "The command line arguments to pass to the program.", "name": "args", "type": "List"}, {"default": "", "description": "A Cloud Storage path in which to store the training outputs and other data  needed for training. This path is passed to your TensorFlow program as the  `job-dir` command-line argument. The benefit of specifying this field is  that Cloud ML validates the path for use in training.", "name": "job_dir", "type": "GCSPath"}, {"default": "", "description": "The version of Python used in training. If not set, the default version is `2.7`. Python `3.5` is available when runtimeVersion is set to `1.4` and above.", "name": "python_version", "type": "String"}, {"default": "", "description": "The Cloud ML Engine runtime version to use for training. If not set, Cloud ML Engine uses the default stable version, 1.0.", "name": "runtime_version", "type": "String"}, {"default": "", "description": "The Docker image to run on the master replica. This image must be in Container Registry.", "name": "master_image_uri", "type": "GCRPath"}, {"default": "", "description": "The Docker image to run on the worker replica. This image must be in Container Registry.", "name": "worker_image_uri", "type": "GCRPath"}, {"default": "", "description": "The input parameters to create a training job. It is the JSON payload  of a [TrainingInput](https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs#TrainingInput)", "name": "training_input", "type": "Dict"}, {"default": "", "description": "The prefix of the generated job id.", "name": "job_id_prefix", "type": "String"}, {"default": "30", "description": "Optional. A time-interval to wait for between calls to get the job status.  Defaults to 30.'", "name": "wait_interval", "type": "Integer"}], "metadata": {"labels": {"add-pod-env": "true"}}, "name": "Submitting a Cloud ML training job as a pipeline step", "outputs": [{"description": "The ID of the created job.", "name": "job_id", "type": "String"}, {"description": "The output path in Cloud Storage of the trainning job, which contains  the trained model files.", "name": "job_dir", "type": "GCSPath"}, {"name": "MLPipeline UI metadata", "type": "UI metadata"}]}
      "labels":
        "add-pod-env": |-
          true
    "name": |-
      submitting-a-cloud-ml-training-job-as-a-pipeline-step
    "outputs":
      "artifacts":
      - "name": |-
          mlpipeline-ui-metadata
        "path": |-
          /mlpipeline-ui-metadata.json
      - "name": |-
          submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_dir
        "path": |-
          /tmp/kfp/output/ml_engine/job_dir.txt
      - "name": |-
          submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id
        "path": |-
          /tmp/kfp/output/ml_engine/job_id.txt
      "parameters":
      - "name": |-
          submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id
        "valueFrom":
          "path": |-
            /tmp/kfp/output/ml_engine/job_id.txt
    "volumes":
    - "name": |-
        gcp-credentials-user-gcp-sa
      "secret":
        "secretName": |-
          user-gcp-sa
  - "container":
      "args":
      - |-
        kfp_component.google.ml_engine
      - |-
        train
      - |-
        --project_id
      - |-
        {{inputs.parameters.project_id}}
      - |-
        --python_module
      - ""
      - |-
        --package_uris
      - ""
      - |-
        --region
      - |-
        {{inputs.parameters.region}}
      - |-
        --args
      - |-
        ["--training_dataset_path", "{{inputs.parameters.bigquery-query-output_gcs_path}}", "--validation_dataset_path", "{{inputs.parameters.bigquery-query-2-output_gcs_path}}", "--alpha", "{{inputs.parameters.retrieve-best-run-alpha}}", "--max_iter", "{{inputs.parameters.retrieve-best-run-max_iter}}", "--hptune", "False"]
      - |-
        --job_dir
      - |-
        {{inputs.parameters.gcs_root}}/jobdir/{{workflow.uid}}
      - |-
        --python_version
      - ""
      - |-
        --runtime_version
      - ""
      - |-
        --master_image_uri
      - |-
        gcr.io/marinas-demo/trainer_image:latest
      - |-
        --worker_image_uri
      - ""
      - |-
        --training_input
      - ""
      - |-
        --job_id_prefix
      - ""
      - |-
        --wait_interval
      - |-
        30
      "command": []
      "env":
      - "name": |-
          KFP_POD_NAME
        "value": |-
          {{pod.name}}
      - "name": |-
          KFP_POD_NAME
        "valueFrom":
          "fieldRef":
            "fieldPath": |-
              metadata.name
      - "name": |-
          KFP_NAMESPACE
        "valueFrom":
          "fieldRef":
            "fieldPath": |-
              metadata.namespace
      - "name": |-
          GOOGLE_APPLICATION_CREDENTIALS
        "value": |-
          /secret/gcp-credentials/user-gcp-sa.json
      - "name": |-
          CLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE
        "value": |-
          /secret/gcp-credentials/user-gcp-sa.json
      "image": |-
        gcr.io/ml-pipeline/ml-pipeline-gcp:9ad7d7dd9776ce75a83712f5723db2ef93ba5c26
      "volumeMounts":
      - "mountPath": |-
          /secret/gcp-credentials
        "name": |-
          gcp-credentials-user-gcp-sa
    "inputs":
      "parameters":
      - "name": |-
          bigquery-query-2-output_gcs_path
      - "name": |-
          bigquery-query-output_gcs_path
      - "name": |-
          gcs_root
      - "name": |-
          project_id
      - "name": |-
          region
      - "name": |-
          retrieve-best-run-alpha
      - "name": |-
          retrieve-best-run-max_iter
    "metadata":
      "annotations":
        "pipelines.kubeflow.org/component_spec": |-
          {"description": "A Kubeflow Pipeline component to submit a Cloud Machine Learning (Cloud ML) \nEngine training job as a step in a pipeline.\n", "inputs": [{"description": "Required. The ID of the parent project of the job.", "name": "project_id", "type": "GCPProjectID"}, {"default": "", "description": "The Python module name to run after installing the packages.", "name": "python_module", "type": "String"}, {"default": "", "description": "The Cloud Storage location of the packages (that contain the training program  and any additional dependencies). The maximum number of package URIs is 100.", "name": "package_uris", "type": "List"}, {"default": "", "description": "The Compute Engine region in which the training job is run.", "name": "region", "type": "GCPRegion"}, {"default": "", "description": "The command line arguments to pass to the program.", "name": "args", "type": "List"}, {"default": "", "description": "A Cloud Storage path in which to store the training outputs and other data  needed for training. This path is passed to your TensorFlow program as the  `job-dir` command-line argument. The benefit of specifying this field is  that Cloud ML validates the path for use in training.", "name": "job_dir", "type": "GCSPath"}, {"default": "", "description": "The version of Python used in training. If not set, the default version is `2.7`. Python `3.5` is available when runtimeVersion is set to `1.4` and above.", "name": "python_version", "type": "String"}, {"default": "", "description": "The Cloud ML Engine runtime version to use for training. If not set, Cloud ML Engine uses the default stable version, 1.0.", "name": "runtime_version", "type": "String"}, {"default": "", "description": "The Docker image to run on the master replica. This image must be in Container Registry.", "name": "master_image_uri", "type": "GCRPath"}, {"default": "", "description": "The Docker image to run on the worker replica. This image must be in Container Registry.", "name": "worker_image_uri", "type": "GCRPath"}, {"default": "", "description": "The input parameters to create a training job. It is the JSON payload  of a [TrainingInput](https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs#TrainingInput)", "name": "training_input", "type": "Dict"}, {"default": "", "description": "The prefix of the generated job id.", "name": "job_id_prefix", "type": "String"}, {"default": "30", "description": "Optional. A time-interval to wait for between calls to get the job status.  Defaults to 30.'", "name": "wait_interval", "type": "Integer"}], "metadata": {"labels": {"add-pod-env": "true"}}, "name": "Submitting a Cloud ML training job as a pipeline step", "outputs": [{"description": "The ID of the created job.", "name": "job_id", "type": "String"}, {"description": "The output path in Cloud Storage of the trainning job, which contains  the trained model files.", "name": "job_dir", "type": "GCSPath"}, {"name": "MLPipeline UI metadata", "type": "UI metadata"}]}
      "labels":
        "add-pod-env": |-
          true
    "name": |-
      submitting-a-cloud-ml-training-job-as-a-pipeline-step-2
    "outputs":
      "artifacts":
      - "name": |-
          mlpipeline-ui-metadata
        "path": |-
          /mlpipeline-ui-metadata.json
      - "name": |-
          submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir
        "path": |-
          /tmp/kfp/output/ml_engine/job_dir.txt
      - "name": |-
          submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_id
        "path": |-
          /tmp/kfp/output/ml_engine/job_id.txt
      "parameters":
      - "name": |-
          submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir
        "valueFrom":
          "path": |-
            /tmp/kfp/output/ml_engine/job_dir.txt
    "volumes":
    - "name": |-
        gcp-credentials-user-gcp-sa
      "secret":
        "secretName": |-
          user-gcp-sa
